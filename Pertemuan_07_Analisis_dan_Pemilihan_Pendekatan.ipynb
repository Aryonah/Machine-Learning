{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pertemuan 07 - Analisis dan Pemilihan Pendekatan Machine Learning\n",
        "\n",
        "##### Aryanahta Putra_22346002\n",
        "\n",
        "## contoh Programnya: \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UirLSlvrjaA"
      },
      "source": [
        "## A. Teknik Evaluasi Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWA3t0rarjaB"
      },
      "source": [
        "####  K-Fold Cross-Validation \n",
        "1.üåÄ K-Fold Cross-Validation\n",
        "\n",
        "üìå Pengertian:\n",
        "Metode untuk mengevaluasi model machine learning dengan cara membagi data jadi beberapa bagian (fold).\n",
        "\n",
        "Contoh: Kalau K=5, maka data dibagi jadi 5 bagian:\n",
        "\n",
        "4 bagian untuk training\n",
        "\n",
        "1 bagian untuk testing\n",
        "\n",
        "Proses ini diulang sebanyak 5 kali (setiap bagian pernah jadi test set)\n",
        "\n",
        "üéØ Tujuan:\n",
        "Agar evaluasi model lebih akurat dan tidak bias karena diuji dari berbagai sudut.\n",
        "#### kodenya:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wOoRPCBhrjaC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.96 (+/- 0.03)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "data = load_iris()\n",
        "X = data.data      # Fitur\n",
        "y = data.target    # Label\n",
        "\n",
        "# Model dan evaluasi\n",
        "model = RandomForestClassifier()\n",
        "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "print(f\"Accuracy: {np.mean(scores):.2f} (+/- {np.std(scores):.2f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE4lxerQrjaE"
      },
      "source": [
        "### Confusion Matrix\n",
        "2.üìä Confusion Matrix\n",
        "\n",
        "üìå Pengertian:\n",
        "Tabel yang menunjukkan hasil prediksi vs data asli dalam klasifikasi. Biasa dipakai untuk mengevaluasi model klasifikasi.\n",
        "\n",
        "üß† Format:\n",
        "\n",
        "Prediksi Positif\tPrediksi Negatif\n",
        "Asli Positif\tTrue Positive (TP)\tFalse Negative (FN)\n",
        "Asli Negatif\tFalse Positive (FP)\tTrue Negative (TN)\n",
        "üìå Istilah penting:\n",
        "TP: Prediksi benar ‚Üí Positif\n",
        "\n",
        "TN: Prediksi benar ‚Üí Negatif\n",
        "\n",
        "FP: Salah prediksi, harusnya negatif tapi dikira positif (false alarm)\n",
        "\n",
        "FN: Salah prediksi, harusnya positif tapi dikira negatif (missed)\n",
        "\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Prediksi\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Y7QNjfrjaF"
      },
      "source": [
        "## B. Pendekatan Evaluasi\n",
        "#### Grid Search\n",
        "3.üõ†Ô∏è Grid Search\n",
        "\n",
        "üìå Pengertian:\n",
        "Metode untuk mencari kombinasi parameter terbaik untuk model machine learning dengan cara mencoba semua kombinasi yang mungkin.\n",
        "\n",
        "üß™ Contoh:\n",
        "Misal kita mau cari kombinasi terbaik:\n",
        "\n",
        "n_estimators: 100, 200\n",
        "\n",
        "max_depth: 5, 10\n",
        "\n",
        "Grid Search akan mencoba semua:\n",
        "\n",
        "(100, 5)\n",
        "\n",
        "(100, 10)\n",
        "\n",
        "(200, 5)\n",
        "\n",
        "(200, 10)\n",
        "\n",
        "‚úÖ Tujuan:\n",
        "Meningkatkan performa model dengan tuning hyperparameter secara sistematis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NcNJmfhrrjaG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'max_depth': None, 'n_estimators': 50}\n",
            "Best Score: 0.95\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 1. Load data\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. Bagi data jadi train dan test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Definisikan model dan parameter grid\n",
        "model = RandomForestClassifier()\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30]\n",
        "}\n",
        "\n",
        "# 4. Grid Search\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 5. Tampilkan hasil\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n95IeUlIrjaG"
      },
      "source": [
        "### Random Search\n",
        "4.üé≤ Random Search\n",
        "\n",
        "üìå Pengertian:\n",
        "Alternatif dari Grid Search. Tapi dia tidak mencoba semua kombinasi, melainkan memilih kombinasi secara acak dari parameter yang tersedia.\n",
        "\n",
        "üü° Kelebihan:\n",
        "Lebih cepat dari Grid Search\n",
        "\n",
        "Cocok kalau kombinasi terlalu banyak dan kamu mau hasil cepat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MPMUYKJErjaH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'n_estimators': 200, 'max_depth': 30, 'bootstrap': True}\n",
            "Best Score: 0.95\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 1. Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Definisikan model dan parameter distribusi\n",
        "model = RandomForestClassifier()\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# 4. Random Search\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy')\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# 5. Cetak hasil\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Score:\", random_search.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrpMDF3ErjaH"
      },
      "source": [
        "\n",
        "### Studi Kasus\n",
        "##### Klasifikasi Teks:\n",
        "- Studi Kasus: Mengklasifikasikan email sebagai spam atau tidak spam.\n",
        "- Pendekatan: Menggunakan Grid Search untuk mengatur parameter seperti alpha pada Naive Bayes dan C pada SVM untuk mendapatkan model terbaik.\n",
        "- Hasil: Meningkatkan akurasi klasifikasi dengan optimasi parameter.\n",
        "\n",
        "##### Prediksi Harga Rumah:\n",
        "- Studi Kasus: Memprediksi harga rumah berdasarkan fitur seperti ukuran, lokasi, dan tahun bangunan.\n",
        "- Pendekatan: Menggunakan Random Search untuk mengoptimalkan parameter pada model random forest dan gradient boosting.\n",
        "- Hasil: Mengurangi kesalahan prediksi (MAE, RMSE) dengan menemukan kombinasi parameter yang optimal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úÖ 1. Klasifikasi Teks ‚Äì Spam vs Non-Spam (dengan Grid Search)\n",
        "Menggunakan:\n",
        "\n",
        "Dataset: Contoh dataset dari sklearn.datasets (jika tidak punya dataset spam asli)\n",
        "\n",
        "Model: Multinomial Naive Bayes & SVM\n",
        "\n",
        "Optimasi: GridSearchCV untuk alpha (NB) dan C (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Params (NB): {'clf__alpha': 0.1, 'tfidf__max_df': 0.7}\n",
            "Best Score (NB): 0.9968531275833563\n",
            "Classification Report (NB):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       111\n",
            "           1       0.99      1.00      1.00       128\n",
            "\n",
            "    accuracy                           1.00       239\n",
            "   macro avg       1.00      1.00      1.00       239\n",
            "weighted avg       1.00      1.00      1.00       239\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load dataset: kita ambil 2 kategori untuk simulasi spam vs non-spam\n",
        "data = fetch_20newsgroups(subset='train', categories=['sci.crypt', 'rec.sport.baseball'])\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pipeline + Grid Search (Naive Bayes)\n",
        "pipeline_nb = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', MultinomialNB())\n",
        "])\n",
        "\n",
        "param_grid_nb = {\n",
        "    'tfidf__max_df': [0.7, 1.0],\n",
        "    'clf__alpha': [0.1, 1.0, 10.0]\n",
        "}\n",
        "\n",
        "grid_nb = GridSearchCV(pipeline_nb, param_grid_nb, cv=5, scoring='accuracy')\n",
        "grid_nb.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Params (NB):\", grid_nb.best_params_)\n",
        "print(\"Best Score (NB):\", grid_nb.best_score_)\n",
        "print(\"Classification Report (NB):\\n\", classification_report(y_test, grid_nb.predict(X_test)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîç Studi Kasus: Klasifikasi Spam vs Non-Spam\n",
        "Bayangkan kita memiliki sekumpulan email atau pesan teks, dan kita ingin membedakan mana yang merupakan spam dan mana yang bukan spam. Ini merupakan masalah klasifikasi biner yang umum di dunia nyata, dan bisa dipecahkan menggunakan Natural Language Processing (NLP) dan Machine Learning.\n",
        "\n",
        "üéØ Tujuan Program\n",
        "Program ini bertujuan untuk:\n",
        "\n",
        "Mengambil data teks dari dua kategori (misalnya: 'sci.crypt' dan 'rec.sport.baseball') sebagai simulasi dari spam dan non-spam.\n",
        "\n",
        "Memproses teks menggunakan TF-IDF Vectorization.\n",
        "\n",
        "Melatih model Naive Bayes untuk klasifikasi teks.\n",
        "\n",
        "Melakukan tuning parameter menggunakan GridSearchCV untuk mencari kombinasi terbaik.\n",
        "\n",
        "Menguji model pada data uji dan melihat performa klasifikasinya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üõ†Ô∏è Penjelasan Komponen Program\n",
        "1. fetch_20newsgroups\n",
        "Digunakan untuk mengambil dataset teks dari internet. Dataset ini berisi berita dari berbagai topik. Di sini kita ambil dua kategori sebagai simulasi spam dan non-spam.\n",
        "\n",
        "2. TfidfVectorizer\n",
        "Mengubah teks menjadi angka yang bisa diproses oleh model. TF-IDF menghitung seberapa penting sebuah kata dalam dokumen dibandingkan seluruh koleksi dokumen.\n",
        "\n",
        "3. MultinomialNB\n",
        "Model Naive Bayes yang sering digunakan untuk teks karena efektif dan cepat.\n",
        "\n",
        "4. Pipeline\n",
        "Menyatukan preprocessing dan model training menjadi satu alur agar mudah dikombinasikan dalam GridSearchCV.\n",
        "\n",
        "5. GridSearchCV\n",
        "Digunakan untuk mencari kombinasi parameter terbaik (seperti alpha untuk Naive Bayes, atau max_df untuk vectorizer) melalui validasi silang (cross-validation).\n",
        "\n",
        "üìà Output yang Diharapkan\n",
        "Output dari program ini akan berupa:\n",
        "\n",
        "Parameter terbaik hasil pencarian grid (misalnya: {'tfidf__max_df': 0.7, 'clf__alpha': 1.0}).\n",
        "\n",
        "Skor akurasi tertinggi saat validasi silang pada data pelatihan (misalnya: 0.92).\n",
        "\n",
        "Laporan klasifikasi pada data uji, termasuk metrik seperti precision, recall, dan f1-score untuk masing-masing kelas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üìö Kesimpulan\n",
        "\n",
        "Program ini adalah contoh penerapan nyata dari teknik klasifikasi teks. Dengan kombinasi preprocessing teks (TF-IDF), model prediktif (Naive Bayes), dan optimasi hyperparameter (GridSearchCV), kita bisa membangun sistem klasifikasi yang cukup akurat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters (RF): {'n_estimators': 100, 'min_samples_split': 5, 'max_depth': 30}\n",
            "Test RMSE (RF): 0.50\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model dan parameter\n",
        "model_rf = RandomForestRegressor()\n",
        "param_dist_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "random_search_rf = RandomizedSearchCV(model_rf, param_distributions=param_dist_rf, n_iter=10, cv=5, scoring='neg_root_mean_squared_error', random_state=42)\n",
        "random_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluasi\n",
        "y_pred = random_search_rf.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(\"Best Parameters (RF):\", random_search_rf.best_params_)\n",
        "print(f\"Test RMSE (RF): {rmse:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üè° Studi Kasus: Prediksi Harga Rumah\n",
        "\n",
        "üìò Latar Belakang\n",
        "\n",
        "Permasalahan ini berkaitan dengan bagaimana kita bisa memprediksi harga rumah berdasarkan sejumlah fitur atau karakteristik seperti:\n",
        "\n",
        "Ukuran rumah (jumlah kamar, jumlah tempat tidur)\n",
        "\n",
        "Lokasi geografis (latitude, longitude)\n",
        "\n",
        "Usia bangunan\n",
        "\n",
        "Jumlah penduduk sekitar\n",
        "\n",
        "dan lain-lain.\n",
        "\n",
        "Ini adalah masalah regresi karena nilai yang diprediksi (harga rumah) adalah angka kontinu, bukan klasifikasi.\n",
        "\n",
        "üéØ Tujuan Program\n",
        "\n",
        "Tujuan dari program ini adalah:\n",
        "\n",
        "Memuat dan mempersiapkan dataset rumah dari California.\n",
        "\n",
        "Melatih model Random Forest Regressor untuk memprediksi harga rumah.\n",
        "\n",
        "Menggunakan Randomized Search CV untuk mencari kombinasi parameter terbaik secara efisien.\n",
        "\n",
        "Mengevaluasi kinerja model berdasarkan Root Mean Squared Error (RMSE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üìö Kesimpulan\n",
        "\n",
        "Program ini menunjukkan cara membangun sistem prediksi harga rumah yang akurat dan efisien. Dengan menggunakan teknik Random Search, kita bisa mengeksplor berbagai parameter tanpa harus mencoba semuanya secara manual, seperti pada Grid Search.\n",
        "\n",
        "Cocok digunakan dalam sistem real-estate, pricing recommendation, atau financial analytics."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
